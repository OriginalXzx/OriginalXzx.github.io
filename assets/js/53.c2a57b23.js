(window.webpackJsonp=window.webpackJsonp||[]).push([[53],{481:function(t,a,s){"use strict";s.r(a);var e=s(1),_=Object(e.a)({},(function(){var t=this,a=t.$createElement,s=t._self._c||a;return s("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[s("h2",{attrs:{id:"_1-前言"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_1-前言"}},[t._v("#")]),t._v(" 1.前言")]),t._v(" "),s("p",[t._v("近来在公司碰到了一次因为系统流量剧增导致线程池线程队列打满，最大线程数都不够用的原因，导致服务超时的情况。尽管我们合理使用了线程池，仍可能由于数据丢失或交易失败惹恼用户。若我们的线程池定义得过大或过小，都有可能让应用程序完全瘫痪。大小合适的线程池允许运行尽可能多的请求，"),s("strong",[t._v("只要硬件和软件支持合理")]),t._v("。换句话说，我们不想在有能力处理时让请求在队列中等待，也不想让运行的请求超出我们的管理能力。究竟线程池应该设置为多大合适呢？")]),t._v(" "),s("h2",{attrs:{id:"_2-利特尔法则（little’s-law）"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_2-利特尔法则（little’s-law）"}},[t._v("#")]),t._v(" 2.利特尔法则（Little’s law）")]),t._v(" "),s("div",{staticClass:"language-math extra-class"},[s("pre",{pre:!0,attrs:{class:"language-text"}},[s("code",[t._v("L = λW\n在一个稳定的系统（L）中，长期的平均请求个数，等于长期的有效抵达率（λ），乘以请求在这个系统中平均的等待时间（W）\n")])])]),s("p",[t._v("对于线程池处理任务来讲")]),t._v(" "),s("div",{staticClass:"language-math extra-class"},[s("pre",{pre:!0,attrs:{class:"language-text"}},[s("code",[t._v("L = qps/1000ms * 任务响应时间(ms)\n")])])]),s("p",[t._v("我们认为线程池是由队列连接的一个或多个服务提供程序，这样我们也可以通过科特尔法则来定义线程池大小。我们只需计算请求到达率和请求处理的平均时间。然后，将上述值放到利特尔法则（Little’s law）就可以算出系统平均请求数。")]),t._v(" "),s("p",[t._v("若请求数小于我们线程池的大小，就相应地减小线程池的大小。与之相反，如果请求数大于线程池大小，事情就有点复杂了,因为不可能无限放大线程池线程数，也不能无限放大线程池队列数，太大了，服务会崩溃掉。所以最好的办法就是通过压力测试来合理的设置线程池大小。")]),t._v(" "),s("h2",{attrs:{id:"_3-设置线程池参数"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_3-设置线程池参数"}},[t._v("#")]),t._v(" 3.设置线程池参数")]),t._v(" "),s("h3",{attrs:{id:"_3-1-线程池处理任务流程"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_3-1-线程池处理任务流程"}},[t._v("#")]),t._v(" 3.1 线程池处理任务流程")]),t._v(" "),s("h3",{attrs:{id:"_3-2-实际业务场景参数："}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_3-2-实际业务场景参数："}},[t._v("#")]),t._v(" 3.2 实际业务场景参数：")]),t._v(" "),s("ul",[s("li",[t._v("tasks: 每秒的任务数，假设是500~1000")]),t._v(" "),s("li",[t._v("taskcost: 每个任务花费的时间，假设为0.1s")]),t._v(" "),s("li",[t._v("responsetime: 系统允许容忍的最大响应时间，假设为1s")])]),t._v(" "),s("h3",{attrs:{id:"_3-3-结合利特尔法则做几个计算："}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_3-3-结合利特尔法则做几个计算："}},[t._v("#")]),t._v(" 3.3 结合利特尔法则做几个计算：")]),t._v(" "),s("ol",[s("li",[t._v("corePoolSize = 每秒需要多少个线程处理？")])]),t._v(" "),s("ul",[s("li",[s("strong",[t._v("threadcount = tasks/(1/taskcost) =tasks*taskcost")]),t._v("   =(500~1000)*0.1 = 50~100 个线程。corePoolSize设置应该大于50")]),t._v(" "),s("li",[t._v("根据8020原则，如果80%的每秒任务数小于800，那么corePoolSize设置为80即可")])]),t._v(" "),s("ol",{attrs:{start:"2"}},[s("li",[t._v("*"),s("em",[t._v("queueCapacity = (corePoolSize/taskcost)"),s("em",[t._v("responsetime")])]),t._v("   = 80/0.1 * 1 = 800 （0.1s 线程池可处理80个任务，1s 线程池可处理800个任务）也就是说队列里的线程可以等待1s，超过了的需要新开线程来执行")])]),t._v(" "),s("ul",[s("li",[t._v("切记不能设置为Integer.MAX_VALUE，这样队列会很大，线程数只会保持在corePoolSize大小，当任务陡增时，不能新开线程来执行，响应时间会随之陡增。")])]),t._v(" "),s("ol",{attrs:{start:"3"}},[s("li",[s("p",[s("strong",[t._v("maxPoolSize = (max(tasks)- queueCapacity - corePoolSize)/(1/taskcost)+corePoolSize")]),t._v("（最大任务数-队列容量-核心线程数）/每个线程每秒处理能力 + 核心线程数= 最大线程数）")])]),t._v(" "),s("li",[s("p",[t._v("rejectedExecutionHandler：根据具体情况来决定，任务不重要可丢弃，任务重要则要利用一些缓冲机制来处理。")])]),t._v(" "),s("li",[s("p",[t._v("keepAliveTime和allowCoreThreadTimeout采用默认通常能满足。")])]),t._v(" "),s("li",[s("p",[t._v("线程池参数极速生成\n"),s("comput-thread-param")],1)])]),t._v(" "),s("h2",{attrs:{id:"_4-示例"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_4-示例"}},[t._v("#")]),t._v(" 4.示例")]),t._v(" "),s("p",[t._v("本次就以本人在公司遇到的case为例，优化线程池")]),t._v(" "),s("h3",{attrs:{id:"_4-1-接口调用链路图"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_4-1-接口调用链路图"}},[t._v("#")]),t._v(" 4.1 接口调用链路图")]),t._v(" "),s("img",{attrs:{src:"/threadCounts/viptuandan.png",width:"80%",height:"auto",div:"",align:"right/"}}),t._v(" "),s("h3",{attrs:{id:"服务调用情况"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#服务调用情况"}},[t._v("#")]),t._v(" 服务调用情况")]),t._v(" "),s("ul",[s("li",[t._v("loadHomeDealGroupList qps 最大出现20 希望系统能承受100qps(系统能承受多大的qps需要压测才能得出数据)  放大分页大小倍数 taskCounts 200")]),t._v(" "),s("li",[t._v("服务响应999线 0.2s")]),t._v(" "),s("li",[t._v("服务最大容忍时间responsetime: 0.5s")])]),t._v(" "),s("p",[t._v("那么在第一个用于调用buildDealInfo线程池参数配置如下：")]),t._v(" "),s("ul",[s("li",[t._v("coreSizePool = 40")]),t._v(" "),s("li",[t._v("queueCapacity = 100")]),t._v(" "),s("li",[t._v("maxPoolSize = 190")])]),t._v(" "),s("p",[t._v("其他服务调用情况")]),t._v(" "),s("ul",[s("li",[t._v("qps 在上一层基础上放大 6倍 taskCounts 1200")]),t._v(" "),s("li",[t._v("服务最大响应时间 80ms")]),t._v(" "),s("li",[t._v("服务最大容忍时间 400ms")])]),t._v(" "),s("p",[t._v("那么在第一个用于调用buildDealInfo线程池参数配置如下：")]),t._v(" "),s("ul",[s("li",[t._v("coreSizePool = 96")]),t._v(" "),s("li",[t._v("queueCapacity = 470")]),t._v(" "),s("li",[t._v("maxPoolSize = 440")])]),t._v(" "),s("h3",{attrs:{id:"压测"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#压测"}},[t._v("#")]),t._v(" 压测")]),t._v(" "),s("p",[t._v("首先压测接口，qps按照预设的缓慢变化，接口十分平稳\n"),s("img",{attrs:{src:"/threadCounts/qpschange.png",width:"80%",height:"auto",div:"",align:"right/"}})]),t._v(" "),s("p",[t._v("当超过我们核心线程数大小能承受的qps时，服务出现长尾相应，平均响应时间缓慢增加\n"),s("img",{attrs:{src:"/threadCounts/hittime.png",width:"80%",height:"auto",div:"",align:"right/"}}),t._v(" "),s("img",{attrs:{src:"/threadCounts/averagetime.png",width:"80%",height:"auto",div:"",align:"right/"}})]),t._v(" "),s("p",[t._v("这里不做极限qps较验，以防压测给依赖服务来了不好影响！")]),t._v(" "),s("blockquote",[s("p",[t._v("实践是验证理论的唯一真理！")])])])}),[],!1,null,null,null);a.default=_.exports}}]);